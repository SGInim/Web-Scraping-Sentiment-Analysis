{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Prediction\n",
    "\n",
    "## Table of Contents:\n",
    "* [0. Problem Description](#Problem)\n",
    "* [1. Exploratory Data Analysis (EDA)](#EDA)\n",
    "* [2. Feature Engineering](#Feat)\n",
    "  * [2.1. Correlation](#Corr)\n",
    "  * [2.2. NZV](#NZV)\n",
    "  * [2.3. Split Train & Test](#Split)\n",
    "  * [2.4. RFE](#RFE)\n",
    "  * [2.5. Standardization & PCA](#PCA)\n",
    "* [3. Predictions](#Pred)\n",
    "  * [3.1. Average Sentiment for iPhone](#avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a class=\"anchor\" id=\"Problem\"> 0. Problem Description </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind this project is to scrap the web to extract pages containing previously chosen words related to sentiment or feeling about a certain phone, so that we could provide an answer of the type ‘brand X is preferred among people at this moment’.\n",
    "\n",
    "An NGO called Common Crawl, collects all the internet’s webpages (billions) created each month, once a month. I used this service to download last month’s data (only the data that matched our conditions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import plotly.express as px\n",
    "\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# RFE & MODELLING\n",
    "from sklearn.preprocessing import MinMaxScaler #Standardization\n",
    "from sklearn.feature_selection import VarianceThreshold #NZV\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Cross Validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "random.seed(203)\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/home/s/Desktop/Dropbox/Documents/Python/Mod4 Ubiqum/Datasets')\n",
    "\n",
    "galaxy = pd.read_csv('galaxy_smallmatrix_labeled_9d.csv')\n",
    "iphone = pd.read_csv('iphone_smallmatrix_labeled_8d.csv')\n",
    "iphone_test = pd.read_csv('concatenated_factors.csv')\n",
    "\n",
    "iphone[\"iphonesentiment\"] = iphone[\"iphonesentiment\"].replace(0,1)\n",
    "iphone[\"iphonesentiment\"] = iphone[\"iphonesentiment\"].replace(5,4)\n",
    "\n",
    "del iphone_test[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a class=\"anchor\" id=\"Feat\"> 2. Feature Engineering </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"Corr\"> 2.1. Correlation </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iphone', 'htcphone', 'nokiacamunc', 'nokiadisneg', 'nokiacampos', 'samsungdispos', 'nokiadispos', 'samsungdisneg', 'nokiadisunc', 'nokiaperunc', 'nokiaperpos', 'iosperunc', 'iosperpos', 'googleperpos']\n",
      "(12973, 45) (53485, 44)\n"
     ]
    }
   ],
   "source": [
    "# Collinear columns WITHOUT any relationship to the dependant variable\n",
    "def find_correlation(df, thresh=0.9):\n",
    "   corrMatrix = iphone.corr()\n",
    "   corrMatrix.loc[:,:] =  np.tril(corrMatrix, k=-1)\n",
    "   already_in = set()\n",
    "   result = []\n",
    "   for col in corrMatrix:\n",
    "       perfect_corr = corrMatrix[col][corrMatrix[col] > thresh].index.tolist()\n",
    "       if perfect_corr and col not in already_in:\n",
    "           already_in.update(set(perfect_corr))\n",
    "           perfect_corr.append(col)\n",
    "           result.append(perfect_corr)\n",
    "   select_nested = [f[1:] for f in result]\n",
    "   select_flat = [i for j in select_nested for i in j]\n",
    "   return select_flat\n",
    "\n",
    "print(find_correlation(iphone, thresh=0.9))\n",
    "\n",
    "#Dropping collinear columns between themselves (from 59 to 44!)\n",
    "iphone_test = iphone_test.drop(columns=find_correlation(iphone, thresh=0.9))\n",
    "\n",
    "iphone = iphone.drop(columns=find_correlation(iphone, thresh=0.9))\n",
    "print(iphone.shape, iphone_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"NZV\"> 2.2. NZV </a>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# NOT USING NZV\n",
    "# Remove columns with Near Zero Variance (NZV)\n",
    "\n",
    "#constant_filter = VarianceThreshold(threshold=0.01) #For Zero Variance, choose 0\n",
    "#constant_filter.fit(iphone.iloc[:,:-1])\n",
    "#\n",
    "#iphone.iloc[:,:-1].columns[constant_filter.get_support()]\n",
    "#constant_columns = [column for column in iphone.iloc[:,:-1].columns\n",
    "#                   if column not in iphone.iloc[:,:-1].columns[constant_filter.get_support()]]\n",
    "#\n",
    "#iphone.iloc[:,:-1] = constant_filter.transform(iphone.iloc[:,:-1]) #This overwrites our data with the NZV columns removed\n",
    "#iphone.iloc[:,:-1] = pd.DataFrame(iphone.iloc[:,:-1])\n",
    "#\n",
    "#iphone_test = constant_filter.transform(iphone_test) #This overwrites our data with the NZV columns removed\n",
    "#iphone_test = pd.DataFrame(iphone_test)\n",
    "#print(iphone.iloc[:,:-1].shape, iphone_test.shape) #This leaves us with 40 columns (from 44, after collinearity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"Split\"> 2.3. Split Train & Test </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining Train & Label\n",
    "x = iphone.iloc[:,:-1] #Good practice to select all columns but the last one\n",
    "y = iphone.iloc[:,-1] #Good practice to get the last column\n",
    "\n",
    "x_train = x\n",
    "y_train = y\n",
    "\n",
    "x_test = iphone_test\n",
    "#Defining Train & Label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12973, 44), (53485, 44))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"RFE\"> 2.4. RFE </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Feature  Ranking\n",
      "0   samsunggalaxy        1\n",
      "41      iosperneg        1\n",
      "40      htcperunc        1\n",
      "37   iphoneperunc        1\n",
      "36      htcperneg        1\n",
      "32   iphoneperneg        1\n",
      "31      htcperpos        1\n",
      "29  samsungperpos        1\n",
      "28   iphoneperpos        1\n",
      "27      htcdisunc        1\n",
      "24   iphonedisunc        1\n",
      "23      htcdisneg        1\n",
      "20      htcdispos        1\n",
      "18   iphonedispos        1\n",
      "21   iphonedisneg        1\n",
      "1      sonyxperia        1\n",
      "13      htccamneg        1\n",
      "3             ios        1\n",
      "4   googleandroid        1\n",
      "5    iphonecampos        1\n",
      "8       htccampos        1\n",
      "14   iphonecamunc        1\n",
      "9    iphonecamneg        2\n",
      "15  samsungcamunc        3\n",
      "17      htccamunc        3\n",
      "6   samsungcampos        3\n",
      "42   googleperneg        4\n",
      "25  samsungdisunc        4\n",
      "30     sonyperpos        4\n",
      "2     nokialumina        5\n",
      "7      sonycampos        5\n",
      "10  samsungcamneg        5\n",
      "33  samsungperneg        6\n",
      "38  samsungperunc        6\n",
      "43   googleperunc        6\n",
      "34     sonyperneg        7\n",
      "35    nokiaperneg        7\n",
      "19     sonydispos        7\n",
      "22     sonydisneg        8\n",
      "12    nokiacamneg        8\n",
      "16     sonycamunc        8\n",
      "11     sonycamneg        9\n",
      "39     sonyperunc        9\n",
      "26     sonydisunc        9\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=0)\n",
    "rfe = RFE(estimator=RF, step=3)\n",
    "rfe = rfe.fit(x_train, y_train)\n",
    "## print summaries for the selection of attributes\n",
    "selected_rfe = pd.DataFrame({'Feature': list(x_train.columns),'Ranking': rfe.ranking_})\n",
    "\n",
    "print(selected_rfe.sort_values(by='Ranking'))\n",
    "x_train = rfe.transform(x_train)\n",
    "x_test = rfe.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"PCA\"> 2.5. Standardization & PCA </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand = MinMaxScaler().fit(x_train)\n",
    "x_train = stand.transform(x_train)\n",
    "pca = PCA(0.999)\n",
    "pca.fit(x_train)\n",
    "x_train = pd.DataFrame(pca.transform(x_train))\n",
    "#Test\n",
    "x_test = stand.transform(x_test)\n",
    "x_test = pd.DataFrame(pca.transform(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a class=\"anchor\" id=\"Pred\"> 3. Predictions </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST\n",
    "RF = RandomForestClassifier(n_estimators =100).fit(x_train,y_train)\n",
    "#print(cross_val_score(RF_B, x_train, y_train['galaxysentiment'], cv=10))\n",
    "\n",
    "#Predictions\n",
    "RF_pred = RF.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a class=\"anchor\" id=\"avg\"> 3.1. Average sentiment for iPhone </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.111283537440404"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(RF_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
